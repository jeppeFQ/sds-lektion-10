{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12df754c-ea74-4201-864a-edf764dedf71",
   "metadata": {},
   "source": [
    "# Introduktion til `spaCy` \n",
    "\n",
    "\"spaCy\" indeholder forskellige sprogmodeller - herunder en dansk sprogmodel.\n",
    "\n",
    "Overordnet virker spaCy ved, at man specificerer en sprogmodel samt nogen \"processors\", som modellen skal indeholde. \n",
    "\n",
    "SpaCy's sprogmodeller indeholder blandt andet:\n",
    "- Tokenizer (inddeling i enkeltord)\n",
    "- Lemmatizer (konvertering til navneform)\n",
    "- Part-Of-Speech tagging (POS-tagging) (identificering af ordtyper)\n",
    "- Dependency parsing (sætningskonstruktion)\n",
    "- Named-Entity-Recognition (NER) (udledning af \"named entities\", fx personer og organisationer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde3b52-f3df-444d-aea9-1a34b958b3fb",
   "metadata": {},
   "source": [
    "## Brug af spaCy i Python\n",
    "\n",
    "1. Indlæs sprogmodel\n",
    "2. Analysér tekstykke\n",
    "3. Inspicér resultater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d1ace3-ef6f-4c1b-9281-84d9c5062257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "#!python -m spacy download 'da_core_news_sm' # evt. installer sprogmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ad79f-3504-45dd-9b11-d6fbceabddb0",
   "metadata": {},
   "source": [
    "Når sprogmodellen er hentet, kan vi bruge den ved at indlæse modellen. Som standard indlæses modellen med alle processerne, men det er muligt at aktivere/deaktivere specifikke processer.\n",
    "\n",
    "Efter modellen er defineret, kan man lade sprogmodellen analysere tekst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96aa5839-983a-4324-9a88-41f47a1a52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"da_core_news_sm\") # Definerer model\n",
    "\n",
    "doc = nlp('Politiet har givet borgerne råd') # Analyserer tekst med model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a88b6fb-bf12-4301-90ca-9ab4f8482682",
   "metadata": {},
   "source": [
    "Når modellen anvendes på et stykke tekst, behandler den tekststykket med de forskellige processors, som er en del af sprogmodellen (som standard for dansk: tokenizer, part-of-speech tagging, lemmatizer og dependency parsing).\n",
    "\n",
    "Outputtet (`doc`) indeholder de forskellige værdier, som er udledt af teksten, som attributes (et attribute for token, et for lemma, et for POS-tag osv.).\n",
    "\n",
    "Vi kan fx visualisere sætningskonstruktionen med funktionen `displacy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b38ed78-8515-4ada-89e9-326b8b527368",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"da\" id=\"22dffbb539384d0db4090dd06b1234cb-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Politiet</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">har</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">givet</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">borgerne</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">råd</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-22dffbb539384d0db4090dd06b1234cb-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-22dffbb539384d0db4090dd06b1234cb-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-22dffbb539384d0db4090dd06b1234cb-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-22dffbb539384d0db4090dd06b1234cb-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-22dffbb539384d0db4090dd06b1234cb-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-22dffbb539384d0db4090dd06b1234cb-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">iobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy # skal indlæses separat\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(displacy.render(doc, style='dep')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e7afbf-4f67-47d0-b9fc-cb373a4cc290",
   "metadata": {},
   "source": [
    "## Lemmatizing\n",
    "\n",
    "Et ords \"lemma\" er dets grammatiske stamme (fx \"er\"->\"være\", \"spiste\"->\"spise\"). SpaCy's sprogmodeller indeholder typisk en indbygget ordbog til at finde stammen for de enkelte ord. Et ords \"lemma\" er gem under attributtet `.lemma_` for hvert ord:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "602c77ac-1f93-4aad-905e-0a01c6654d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politiet        politi\n",
      "har             have\n",
      "givet           give\n",
      "borgerne        borger\n",
      "råd             råd\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(f'{word.text:<15} {word.lemma_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25dccf-d22e-49e1-81db-495353f9d684",
   "metadata": {},
   "source": [
    "## Part-of-speech tags\n",
    "\n",
    "SpaCy tagger automatisk hvert ord med sin ordklasse (\"part-of-speech\"-tag/POS-tag). Disse er gemt under attributtet `.pos_` for hvert ord:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a32e3b3c-2fb7-4d22-8e4d-7dae8fd82cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politiet        NOUN\n",
      "har             AUX\n",
      "givet           VERB\n",
      "borgerne        NOUN\n",
      "råd             NOUN\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(f'{word.text:<15} {word.pos_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ffb0f-388c-4e5b-9574-e53bb7dd52d3",
   "metadata": {},
   "source": [
    "Part-of-speech tagging virker ved, at modellen i forvejen er trænet på danske tekster, og derfor har \"set\" de forskellige ord i kontekst før. Som det kan ses, er modellen dog ikke perfekt (fx \"trygge\" er angivet som navneord (NOUN), selvom der her er tale om et tillægsord (ADJ)).\n",
    "\n",
    "Part-of-speech tagging tillader fx at isolere visse ord i et stykke tekst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3b6e233-757b-4146-b890-95ecc2c1d4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "givet           VERB\n"
     ]
    }
   ],
   "source": [
    "keep_tags = ['VERB']\n",
    "keep_words = []\n",
    "\n",
    "for word in doc:\n",
    "    if word.pos_ in keep_tags:\n",
    "        keep_words.append(word)\n",
    "\n",
    "for word in keep_words:\n",
    "    print(f'{word.text:<15} {word.pos_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c8c35-f967-495d-924e-ac3d735d1119",
   "metadata": {},
   "source": [
    "## Dependency parsing\n",
    "\n",
    "SpaCy laver også analyse af sætningskonstruktion (dependency parsing). Hvilken del af sætningen, som ordene er analyseret frem til, kan tilgås af attribut `.dep_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f68e5599-d664-4ce2-91d3-9e9344346ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politiet        nsubj\n",
      "har             aux\n",
      "givet           ROOT\n",
      "borgerne        iobj\n",
      "råd             ROOT\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(f'{word.text:<15} {word.dep_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac7f0e-e5d8-4e97-b040-ff4827e2bea6",
   "metadata": {},
   "source": [
    "## Named entities\n",
    "\n",
    "\"Named entities\" kan groft sagt forstås som \"meningsfulde enheder\" i teksten. Det kan fx være personer, organisationer eller steder. Ligesom ved part-of-speech tagging, fungerer \"named entity recognition\" ved, at modellen enten har set disse enheder før eller er bekendt med, hvordan sådanne enheder fremgår i sætningen (hvor er de i sætningskonstruktionen, hvilke ordklasser er de associeret med).\n",
    "\n",
    "Alle ord i en tekst er ikke en \"named entity\". Named entities kan tilgås gennem attributtet `ents` for det behandlede stykke tekst (`doc`). Fra dette kan ses, hvilke enheder er udledt, og hvordan de er kategoriseret:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57bb9d87-0289-43b3-a6c9-82e335303006",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marie Serup     PER\n",
      "Løkke           LOC\n",
      "DR's            ORG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Søs Marie Serup, politisk kommentator og tidligere særlig rådgiver for Løkke, fortalte i fredags i DR's nyhedspodcast 'Genstart' om hans evne til altid at komme tilbage i politik.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f'{ent.text:<15} {ent.label_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec1f35-59ce-461a-8f21-8ce64ec3afa4",
   "metadata": {},
   "source": [
    "Denne sprogmodel arbejder med fire named entity tags:\n",
    "- LOC: Steder\n",
    "- ORG: Organisationer\n",
    "- PER: Personer\n",
    "- MISC: Andet\n",
    "\n",
    "Af ovenstående ses, at modellen identificerer \"DR\" som en organisation, hvilket er meget passende. Derudover genkender den \"Marie Serup\" som person, men har udeladt fornavnet \"Søs\". Dog er \"Løkke\" fejlklassificeret som et sted (LOC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33454436-b903-4997-a4c6-155b93c7e9ce",
   "metadata": {},
   "source": [
    "## Tilpas spaCy pipeline\n",
    "\n",
    "Når man definerer `nlp`-funktionen (sit spaCy pipeline) med en sprogmodel (`spacy.load()`), inkluderes alle komponenter som standard. Hvis man kun er interesseret i specifikke komponenter, kan man slå dele af pipeline til eller fra. \n",
    "\n",
    "Se de forskellige komponenter her: [https://spacy.io/usage/processing-pipelines#built-in](https://spacy.io/usage/processing-pipelines#built-in).\n",
    "\n",
    "Når man arbejder med store mængder tekstdata, kan det give mening at forsimple funktionen for at spare beregningstid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067c87f1-9904-436e-b3dd-77cb4de9abd2",
   "metadata": {},
   "source": [
    "### Slå komponenter fra\n",
    "\n",
    "Man slår komponenter fra ved brug af argumentet `disable`, når man indlæser modellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66b57d8f-dac2-410c-9ad5-5f48d57495ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"da_core_news_sm\", disable = ['parser'])\n",
    "\n",
    "doc = nlp('Politiet har givet borgerne råd') # analysér tekststykke med nyt pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a78e761-5259-4002-8a0d-95225b490667",
   "metadata": {},
   "source": [
    "`doc` indeholder stadig lemma, da lemmatizer stadig er slået til."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b27130be-a3ce-4d03-b4a0-aba72c3f52c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politiet        politi\n",
      "har             have\n",
      "givet           give\n",
      "borgerne        borger\n",
      "råd             råd\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(f'{word.text:<15} {word.lemma_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a6c074-2e6e-4a83-b797-8637097e4562",
   "metadata": {},
   "source": [
    "Der er ikke længere nogen dependency labels, da `parser` er slået fra (returnerer None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba76f18c-5bb0-46b2-aec7-8e6d8e939285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politiet        \n",
      "har             \n",
      "givet           \n",
      "borgerne        \n",
      "råd             \n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(f'{word.text:<15} {word.dep_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b4c1b-7b05-4468-adbe-39276e63c0ca",
   "metadata": {},
   "source": [
    "### Slå komponenter til\n",
    "\n",
    "Man slår komponenter til ved brug af argumentet `enable`, når man indlæser modellen. Alle komponenter, som ikke listes, slås fra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ceb9cc4-df6f-423d-8997-cc9162355e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"da_core_news_sm\", enable = ['parser'])\n",
    "\n",
    "doc = nlp('Politiet har givet borgerne råd') # analysér tekststykke med nyt pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a77756-20b3-4384-b9be-f87d0d6b42da",
   "metadata": {},
   "source": [
    "`doc` indeholder nu ikke lemma, da kun parser er slået til."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2dcfc0b-8cc8-427b-9a01-19ce7ac60c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politiet        \n",
      "har             \n",
      "givet           \n",
      "borgerne        \n",
      "råd             \n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(f'{word.text:<15} {word.lemma_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d2f094-c34b-4e2a-a490-188fc678e0bb",
   "metadata": {},
   "source": [
    "Der er dependency labels, da parser er slået til."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85911460-8bab-4161-b45e-60b63fa6cc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politiet        case\n",
      "har             case\n",
      "givet           case\n",
      "borgerne        ROOT\n",
      "råd             punct\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(f'{word.text:<15} {word.dep_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5383ed55-4104-49e8-9cce-831c8cb1cd63",
   "metadata": {},
   "source": [
    "### Tokenizer som særskilt funktion\n",
    "\n",
    "Hvis man blot vil bruge tokenizeren, kan denne tilgås direkte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5167a45-3bc3-41c8-a3b0-38b115540c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"da_core_news_sm\")\n",
    "\n",
    "tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efe4bf5d-53c9-4be9-8398-dc65b36068bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politiet har givet borgerne råd"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('Politiet har givet borgerne råd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e983f760-b3f8-430c-87ef-d6d3597336a7",
   "metadata": {},
   "source": [
    "Tokenizeren returnerer stadig et `doc` objekt, men da den kun giver tokens tilbage, kan man tvinge output om til en liste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2aa64de1-7555-4d2c-9994-375a0e26dcae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Politiet, har, givet, borgerne, råd]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer('Politiet har givet borgerne råd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ea42f-2a61-4ba9-a891-b51f25d4a9b7",
   "metadata": {},
   "source": [
    "## spaCy pipeline på flere stykker tekst\n",
    "\n",
    "Pipeline-funktionen (`nlp`) virker kun på ét stykke tekst. Afhængig af datastruktur, kan man anvende pipeline på flere stykker tekst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46e737a0-263d-4ed6-99b4-f1c26f24a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'Smileyordningen får stor makeover: Kontrolrapporten forsvinder og en QR-kode kommer til',\n",
    "    'Bro skal rives ned: Motorvej spærres i 14 timer',\n",
    "    'Indonesien er klar med Sydøstasiens første højhastighedstog',\n",
    "    'Politiet dropper efterforskning af hospital og region efter kræftskandale',\n",
    "    'Hvad foregår der i Ikast? De kom med på et wildcard, og nu topper de hele baduljen'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea6b682-9a23-42d7-9b73-37cad9582b39",
   "metadata": {},
   "source": [
    "### Lister\n",
    "\n",
    "Hvis tekster er i en liste, kan man bruge metoden `.pipe()` til at anvende pipeline på flere tekststykker.\n",
    "\n",
    "`.pipe()` returnerer et \"generator object\". Dette er en speciel type objekt i Python, som kun giver et output, når den bliver kaldt (en måde at spare hukommelse). Hvis vi fx vil have teksterne tilbage som en liste af `doc`-objekter, kan man tvinge output om til en liste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6db7ced2-3962-4baf-b521-b117c21402c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(nlp.pipe(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70b74d4a-e1b2-4610-80ad-fb46f49f4fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smileyordningen      NOUN\n",
      "får                  VERB\n",
      "stor                 ADJ\n",
      "makeover             NOUN\n",
      ":                    PUNCT\n",
      "Kontrolrapporten     NOUN\n",
      "forsvinder           VERB\n",
      "og                   CCONJ\n",
      "en                   DET\n",
      "QR-kode              NOUN\n",
      "kommer               VERB\n",
      "til                  ADP\n"
     ]
    }
   ],
   "source": [
    "for word in docs[0]:\n",
    "    print(f'{word.text:<20} {word.pos_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5e97969-e3da-4098-b69f-4a075e3189dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro                  ADV\n",
      "skal                 AUX\n",
      "rives                VERB\n",
      "ned                  ADV\n",
      ":                    PUNCT\n",
      "Motorvej             PROPN\n",
      "spærres              VERB\n",
      "i                    ADP\n",
      "14                   NUM\n",
      "timer                NOUN\n"
     ]
    }
   ],
   "source": [
    "for word in docs[1]:\n",
    "    print(f'{word.text:<20} {word.pos_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ae38f-dbab-4979-b611-aab0eef86df0",
   "metadata": {},
   "source": [
    "### Pandas Series\n",
    "\n",
    "Hvis tekster er i en pandas Series, kan man bruge metoden `.apply()` i pandas. Dog forventer `.apply()`, at der kun gives ét output. Derfor bør man lave en wrapper-funktion, så man kan udpege, hvad der skal gives som output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38ba6e71-fbac-4afa-8a01-2e8abeff06ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dan funktion til at hente named entities\n",
    "\n",
    "def get_ents(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    ents = list(doc.ents)\n",
    "\n",
    "    return(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7f763b4-ee6d-4b15-886a-403385d95280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [(QR-kode)]\n",
       "1      [(Motorvej)]\n",
       "2    [(Indonesien)]\n",
       "3                []\n",
       "4         [(Ikast)]\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "texts_s = pd.Series(texts) # konvertér liste til series\n",
    "\n",
    "texts_s.apply(get_ents) # anvend funktion på series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bb0626",
   "metadata": {},
   "source": [
    "# Arbejde med større pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8835a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jeppefl/Library/CloudStorage/OneDrive-AalborgUniversitet/01_work/01_undervisning/02_sds1/03_data/spam.csv', encoding='cp1252')\n",
    "\n",
    "df = df[['v1', 'v2']].copy()\n",
    "df.columns = ['label', 'message']\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29c4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bada2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indlæs engelsk model (da beskederne er på engelsk)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "print(f\"Pipeline komponenter: {nlp.pipe_names}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fd88ba",
   "metadata": {},
   "source": [
    "## Tilgang 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bc9714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag et lille subset først for at teste\n",
    "df_small = df.head(100).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpel wrapper funktion\n",
    "def process_with_spacy(text):\n",
    "    return nlp(text)\n",
    "\n",
    "df_small['doc'] = df_small['message'].apply(process_with_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_doc = df_small['doc'].iloc[0]\n",
    "print(f\"Tekst: {first_doc.text[:100]}...\")\n",
    "print(f\"Antal tokens: {len(first_doc)}\")\n",
    "print(f\"Antal sætninger: {len(list(first_doc.sents))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ac732",
   "metadata": {},
   "source": [
    "## Tilgang 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medium = df.head(500).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaae6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(nlp.pipe(df_medium['message']))\n",
    "df_medium['doc'] = docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a41ccf",
   "metadata": {},
   "source": [
    "## TOKENS OG LEMMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTokens og lemmas:\")\n",
    "\n",
    "def extract_tokens(doc):\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "def extract_lemmas(doc):\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "df_medium['tokens'] = df_medium['doc'].apply(extract_tokens)\n",
    "df_medium['lemmas'] = df_medium['doc'].apply(extract_lemmas)\n",
    "df_medium['n_tokens'] = df_medium['tokens'].apply(len)\n",
    "\n",
    "print(df_medium[['message', 'n_tokens']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba3086",
   "metadata": {},
   "source": [
    "## PART-OF-SPEECH TAGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPart-of-speech tags:\")\n",
    "\n",
    "def extract_pos_tags(doc):\n",
    "    return [token.pos_ for token in doc]\n",
    "\n",
    "def count_verbs(doc):\n",
    "    return sum(1 for token in doc if token.pos_ == 'VERB')\n",
    "\n",
    "def count_nouns(doc):\n",
    "    return sum(1 for token in doc if token.pos_ == 'NOUN')\n",
    "\n",
    "df_medium['pos_tags'] = df_medium['doc'].apply(extract_pos_tags)\n",
    "df_medium['n_verbs'] = df_medium['doc'].apply(count_verbs)\n",
    "df_medium['n_nouns'] = df_medium['doc'].apply(count_nouns)\n",
    "\n",
    "print(df_medium[['message', 'n_verbs', 'n_nouns']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283385db",
   "metadata": {},
   "source": [
    "## NAMED ENTITIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNamed entities:\")\n",
    "\n",
    "def extract_entities(doc):\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "def count_entities(doc):\n",
    "    return len(doc.ents)\n",
    "\n",
    "df_medium['entities'] = df_medium['doc'].apply(extract_entities)\n",
    "df_medium['n_entities'] = df_medium['doc'].apply(count_entities)\n",
    "\n",
    "print(df_medium[['message', 'entities']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39681d9b",
   "metadata": {},
   "source": [
    "## SÆTNINGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSætninger:\")\n",
    "\n",
    "def extract_sentences(doc):\n",
    "    return [sent.text for sent in doc.sents]\n",
    "\n",
    "def count_sentences(doc):\n",
    "    return len(list(doc.sents))\n",
    "\n",
    "df_medium['sentences'] = df_medium['doc'].apply(extract_sentences)\n",
    "df_medium['n_sentences'] = df_medium['doc'].apply(count_sentences)\n",
    "\n",
    "print(df_medium[['message', 'n_sentences']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b094d82",
   "metadata": {},
   "source": [
    "# Analyse eksempel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa35237",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = df_medium.groupby('label').agg({\n",
    "    'n_tokens': 'mean',\n",
    "    'n_verbs': 'mean',\n",
    "    'n_nouns': 'mean',\n",
    "    'n_entities': 'mean',\n",
    "    'n_sentences': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nGennemsnitlige værdier:\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_only_content_words(doc):\n",
    "    \"\"\"Behold kun substantiver, verber, adjektiver og adverbier\"\"\"\n",
    "    keep_tags = ['NOUN', 'VERB', 'ADJ', 'ADV']\n",
    "    return [token.lemma_ for token in doc if token.pos_ in keep_tags]\n",
    "\n",
    "df_medium['content_words'] = df_medium['doc'].apply(keep_only_content_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c228b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\Original vs filtreret:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nBesked {i+1}:\")\n",
    "    print(f\"Original: {df_medium['message'].iloc[i][:80]}...\")\n",
    "    print(f\"Content words: {' '.join(df_medium['content_words'].iloc[i][:15])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c8ea62",
   "metadata": {},
   "source": [
    "### Optimering af pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hvis vi kun skal bruge tokens og POS tags, kan vi deaktivere parser og NER\n",
    "nlp_optimized = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a1104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.head(500).copy()\n",
    "docs_optimized = list(nlp_optimized.pipe(df_test['message']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9c31e6",
   "metadata": {},
   "source": [
    "### For store datasets (>10,000 rækker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969e9679",
   "metadata": {},
   "source": [
    "1. BRUG .pipe() I STEDET FOR .apply()\n",
    "2. BATCH SIZE: list(nlp.pipe(texts, batch_size=100))\n",
    "3. DEAKTIVER UNØDVENDIGE KOMPONENTER\n",
    "5. GEM RESULTATER (Genberegn ikke hver gang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60665b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_large_dataframe(df, text_column, batch_size=100):\n",
    "    \"\"\"Optimeret funktion til at processere store DataFrames\"\"\"\n",
    "    \n",
    "    # Brug optimeret pipeline\n",
    "    nlp_fast = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    \n",
    "    # Process med pipe og batch_size\n",
    "    docs = list(nlp_fast.pipe(df[text_column], batch_size=batch_size))\n",
    "    \n",
    "    # Udtræk features direkte\n",
    "    results = {\n",
    "        'tokens': [[token.text for token in doc] for doc in docs],\n",
    "        'lemmas': [[token.lemma_ for token in doc] for doc in docs],\n",
    "        'pos_tags': [[token.pos_ for token in doc] for doc in docs],\n",
    "        'n_tokens': [len(doc) for doc in docs]\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c847cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large = df.head(1000).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = process_large_dataframe(df_large, 'message', batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fb8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tilføj resultater til dataframe\n",
    "for key, values in results.items():\n",
    "    df_large[key] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc726a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gem dataframe med alle features\n",
    "# Fjern 'doc' kolonnen da den ikke kan gemmes direkte\n",
    "\n",
    "#df_to_save = df_medium.drop('doc', axis=1)\n",
    "#df_to_save.to_csv('spam_spacy_features.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2d43a",
   "metadata": {},
   "source": [
    "# Bud på en meningsfuld analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da548d",
   "metadata": {},
   "source": [
    "> **Bruger spam-beskeder mere imperative verber (kommandoer) end normale beskeder?**\n",
    "\n",
    "> Indeholder spam flere entiteter som navne/organisationer for at virke legitime?\n",
    "\n",
    "> Er spam-beskeder kortere og mere \"aggressive\" i deres sprogbrug?\n",
    "\n",
    "> **Hvilke konkrete ord og grammatiske mønstre karakteriserer spam?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc500fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['ner'])  # Aktivér ner igen senere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process beskederne (brug subset for test, fjern [:1000] for fuld analyse)\n",
    "df_analysis = df[:1000].copy()\n",
    "docs = list(nlp.pipe(df_analysis['message'], batch_size=50))\n",
    "df_analysis['doc'] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b3f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basis features\n",
    "df_analysis['n_tokens'] = df_analysis['doc'].apply(lambda doc: len(doc))\n",
    "df_analysis['n_sentences'] = df_analysis['doc'].apply(lambda doc: len(list(doc.sents)))\n",
    "df_analysis['avg_sentence_length'] = df_analysis['n_tokens'] / df_analysis['n_sentences']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERB features (vigtige for at identificere kommandoer)\n",
    "def count_imperatives(doc):\n",
    "    \"\"\"Tæl imperative verber (kommandoer som 'Call', 'Text', 'Click')\"\"\"\n",
    "    imperatives = 0\n",
    "    for sent in doc.sents:\n",
    "        tokens = list(sent)\n",
    "        if len(tokens) > 0:\n",
    "            # Imperativer starter ofte sætningen og er verber\n",
    "            if tokens[0].pos_ == 'VERB' and tokens[0].tag_ == 'VB':\n",
    "                imperatives += 1\n",
    "    return imperatives\n",
    "\n",
    "def count_verbs_by_type(doc):\n",
    "    \"\"\"Tæl forskellige typer af verber\"\"\"\n",
    "    verb_types = {'VB': 0, 'VBG': 0, 'VBD': 0, 'VBN': 0, 'VBP': 0, 'VBZ': 0}\n",
    "    for token in doc:\n",
    "        if token.tag_ in verb_types:\n",
    "            verb_types[token.tag_] += 1\n",
    "    return verb_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b43210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis['n_imperatives'] = df_analysis['doc'].apply(count_imperatives)\n",
    "df_analysis['n_verbs'] = df_analysis['doc'].apply(lambda doc: sum(1 for t in doc if t.pos_ == 'VERB'))\n",
    "df_analysis['verb_ratio'] = df_analysis['n_verbs'] / df_analysis['n_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urgency markers (ord der skaber tidspres)\n",
    "urgency_words = ['now', 'urgent', 'immediately', 'today', 'limited', 'expires', 'hurry', 'asap', 'quick']\n",
    "\n",
    "def count_urgency_words(doc):\n",
    "    \"\"\"Tæl ord der skaber følelse af tidspres\"\"\"\n",
    "    text_lower = doc.text.lower()\n",
    "    return sum(1 for word in urgency_words if word in text_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e206d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis['n_urgency'] = df_analysis['doc'].apply(count_urgency_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785cf0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incentive markers (belønninger og gratis tilbud)\n",
    "incentive_words = ['free', 'win', 'prize', 'bonus', 'gift', 'cash', 'claim', 'reward']\n",
    "\n",
    "def count_incentive_words(doc):\n",
    "    \"\"\"Tæl ord der lover belønninger\"\"\"\n",
    "    text_lower = doc.text.lower()\n",
    "    return sum(1 for word in incentive_words if word in text_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d0dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis['n_incentives'] = df_analysis['doc'].apply(count_incentive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special characters (tegn som !, ?, £, $)\n",
    "def count_special_chars(text):\n",
    "    \"\"\"Tæl særlige tegn der bruges til at tiltrække opmærksomhed\"\"\"\n",
    "    special = ['!', '?', '£', '$', '*', '#']\n",
    "    return sum(text.count(char) for char in special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c466b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis['n_special_chars'] = df_analysis['message'].apply(count_special_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d53ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tal og numre (ofte telefonnumre, koder)\n",
    "def count_numbers(doc):\n",
    "    \"\"\"Tæl numeriske tokens\"\"\"\n",
    "    return sum(1 for token in doc if token.like_num or token.is_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601238a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis['n_numbers'] = df_analysis['doc'].apply(count_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4eac9f",
   "metadata": {},
   "source": [
    "### Sammenligning af sproglige mønstre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = df_analysis.groupby('label').agg({\n",
    "    'n_tokens': 'mean',\n",
    "    'n_sentences': 'mean',\n",
    "    'avg_sentence_length': 'mean',\n",
    "    'n_imperatives': 'mean',\n",
    "    'verb_ratio': 'mean',\n",
    "    'n_urgency': 'mean',\n",
    "    'n_incentives': 'mean',\n",
    "    'n_special_chars': 'mean',\n",
    "    'n_numbers': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nGennemsnitlige værdier (spam vs ham):\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c53f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beregn forskelle\n",
    "spam_data = df_analysis[df_analysis['label'] == 'spam']\n",
    "ham_data = df_analysis[df_analysis['label'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nANALYSE 1. IMPERATIVER (kommandoer):\")\n",
    "print(f\"   Spam: {spam_data['n_imperatives'].mean():.2f} per besked\")\n",
    "print(f\"   Ham: {ham_data['n_imperatives'].mean():.2f} per besked\")\n",
    "print(f\"   Spam bruger {(spam_data['n_imperatives'].mean() / ham_data['n_imperatives'].mean()):.1f}x flere kommandoer\")\n",
    "\n",
    "print(f\"\\nANALYSE 2. URGENCY (tidspres):\")\n",
    "print(f\"   Spam: {spam_data['n_urgency'].mean():.2f} urgency-ord per besked\")\n",
    "print(f\"   Ham: {ham_data['n_urgency'].mean():.2f} urgency-ord per besked\")\n",
    "spam_urgency_pct = (spam_data['n_urgency'] > 0).sum() / len(spam_data) * 100\n",
    "ham_urgency_pct = (ham_data['n_urgency'] > 0).sum() / len(ham_data) * 100\n",
    "print(f\"   {spam_urgency_pct:.1f}% af spam bruger urgency-sprog vs {ham_urgency_pct:.1f}% af ham\")\n",
    "\n",
    "print(f\"\\nANALYSE 3. INCENTIVER (belønninger):\")\n",
    "print(f\"   Spam: {spam_data['n_incentives'].mean():.2f} incentive-ord per besked\")\n",
    "print(f\"   Ham: {ham_data['n_incentives'].mean():.2f} incentive-ord per besked\")\n",
    "spam_incentive_pct = (spam_data['n_incentives'] > 0).sum() / len(spam_data) * 100\n",
    "print(f\"   {spam_incentive_pct:.1f}% af spam lover belønninger\")\n",
    "\n",
    "print(f\"\\nANALYSE 4. SÆRLIGE TEGN (!, £, $):\")\n",
    "print(f\"   Spam: {spam_data['n_special_chars'].mean():.2f} per besked\")\n",
    "print(f\"   Ham: {ham_data['n_special_chars'].mean():.2f} per besked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_words(doc):\n",
    "    \"\"\"Udtræk indholdsord (substantiver, verber, adjektiver)\"\"\"\n",
    "    return [token.lemma_.lower() for token in doc \n",
    "            if token.pos_ in ['NOUN', 'VERB', 'ADJ'] \n",
    "            and not token.is_stop \n",
    "            and token.is_alpha]\n",
    "\n",
    "spam_words = []\n",
    "ham_words = []\n",
    "\n",
    "for idx, row in df_analysis.iterrows():\n",
    "    words = get_content_words(row['doc'])\n",
    "    if row['label'] == 'spam':\n",
    "        spam_words.extend(words)\n",
    "    else:\n",
    "        ham_words.extend(words)\n",
    "\n",
    "spam_top = Counter(spam_words).most_common(15)\n",
    "ham_top = Counter(ham_words).most_common(15)\n",
    "\n",
    "print(\"\\nTop 15 ord i SPAM:\")\n",
    "for word, count in spam_top:\n",
    "    print(f\"  {word:15} ({count})\")\n",
    "\n",
    "print(\"\\nTop 15 ord i HAM:\")\n",
    "for word, count in ham_top:\n",
    "    print(f\"  {word:15} ({count})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7270ad",
   "metadata": {},
   "source": [
    "## Visualisering af resultater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df146a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Sproglige Manipulationsteknikker i Spam-beskeder', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# Imperatives comparison\n",
    "axes[0, 0].bar(['Ham', 'Spam'], \n",
    "               [ham_data['n_imperatives'].mean(), spam_data['n_imperatives'].mean()],\n",
    "               color=['#2ecc71', '#e74c3c'], edgecolor='black', linewidth=1.5)\n",
    "axes[0, 0].set_ylabel('Gennemsnit per besked')\n",
    "axes[0, 0].set_title('Imperative Verber (Kommandoer)')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Urgency words\n",
    "axes[0, 1].bar(['Ham', 'Spam'],\n",
    "               [ham_data['n_urgency'].mean(), spam_data['n_urgency'].mean()],\n",
    "               color=['#2ecc71', '#e74c3c'], edgecolor='black', linewidth=1.5)\n",
    "axes[0, 1].set_ylabel('Gennemsnit per besked')\n",
    "axes[0, 1].set_title('Urgency-ord (Tidspres)')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Incentive words\n",
    "axes[0, 2].bar(['Ham', 'Spam'],\n",
    "               [ham_data['n_incentives'].mean(), spam_data['n_incentives'].mean()],\n",
    "               color=['#2ecc71', '#e74c3c'], edgecolor='black', linewidth=1.5)\n",
    "axes[0, 2].set_ylabel('Gennemsnit per besked')\n",
    "axes[0, 2].set_title('Incentive-ord (Belønninger)')\n",
    "axes[0, 2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Message length distribution\n",
    "axes[1, 0].hist(ham_data['n_tokens'], bins=30, alpha=0.6, label='Ham', color='#2ecc71')\n",
    "axes[1, 0].hist(spam_data['n_tokens'], bins=30, alpha=0.6, label='Spam', color='#e74c3c')\n",
    "axes[1, 0].set_xlabel('Antal ord')\n",
    "axes[1, 0].set_ylabel('Antal beskeder')\n",
    "axes[1, 0].set_title('Beskedlængde')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Special characters\n",
    "axes[1, 1].bar(['Ham', 'Spam'],\n",
    "               [ham_data['n_special_chars'].mean(), spam_data['n_special_chars'].mean()],\n",
    "               color=['#2ecc71', '#e74c3c'], edgecolor='black', linewidth=1.5)\n",
    "axes[1, 1].set_ylabel('Gennemsnit per besked')\n",
    "axes[1, 1].set_title('Særlige Tegn (!, £, $)')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Composite spam score\n",
    "axes[1, 2].scatter(spam_data['n_urgency'] + spam_data['n_incentives'], \n",
    "                   spam_data['n_imperatives'],\n",
    "                   alpha=0.5, color='#e74c3c', label='Spam', s=30)\n",
    "axes[1, 2].scatter(ham_data['n_urgency'] + ham_data['n_incentives'],\n",
    "                   ham_data['n_imperatives'],\n",
    "                   alpha=0.5, color='#2ecc71', label='Ham', s=30)\n",
    "axes[1, 2].set_xlabel('Urgency + Incentive ord')\n",
    "axes[1, 2].set_ylabel('Imperative verber')\n",
    "axes[1, 2].set_title('Manipulationsmønstre')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
